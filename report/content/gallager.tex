\section{Gallager regular LDPC codes} \label{sec:gallager_codes}

Gallager's codes are a simple class of \acrshort{ldpc} codes that can achieve
capacity in the large block length regime.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% GENERATION                                                                   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generation}

The codes generated with the Gallager method are constructed as follows.
\begin{enumerate}
    \item Divide the $N$ bit into $\frac{N}{d_c}$ groups of $d_c$ bits. Each of
          these groups defines a parity check equation (and thus the
          $\frac{M}{d_v} \times N$ matrix $\bm{H}_1$).
    \item To create the $\frac{M (d_v -1)}{M}$ parity check equations left,
          permute the columns of $\bm{H}_1$
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SIMULATIONS                                                                  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Montecarlo simulation on the BMC channel}

The objective of this part is to compare two families of Gallager codes of same
length but different rates (see \autoref{tab:gallager_codes}). For each of these
two families, four degree distributions are compared. The results are shown in
\autoref{fig:gallager_bmc}.

TODO : print number of iterations in BP, number of realizations etc...

\begin{table}
    \centering
    \begin{tabular}{c c c c c}
        length $N$           & \# parity bits $M$   & rate                   & $d_v$ & $d_c$ \\
        \hline \hline
        \multirow{4}{*}{768} & \multirow{4}{*}{384} & \multirow{4}{*}{$1/2$} & 1     & 2     \\
                             &                      &                        & 2     & 4     \\
                             &                      &                        & 3     & 6     \\
                             &                      &                        & 4     & 8     \\
        \hline
        \multirow{4}{*}{768} & \multirow{4}{*}{256} & \multirow{4}{*}{$2/3$} & 1     & 3     \\
                             &                      &                        & 2     & 6     \\
                             &                      &                        & 3     & 9     \\
                             &                      &                        & 4     & 12    \\
    \end{tabular}
    \caption{List of studied Gallager codes}
    \label{tab:gallager_codes}
\end{table}


\begin{figure}
    \centering

    \begin{subfigure}{\textwidth}
        \centering
        \input{figures/gallager_rate-0.5.pgf}
        \caption{$R_c = 1/2$}
    \end{subfigure}%

    \begin{subfigure}{\textwidth}
        \centering
        \input{figures/gallager_rate-0.67.pgf}
        \caption{$R_c = 2/3$}
    \end{subfigure}%
    \caption{%
        Montecarlo simulation of a Gallager codes of length $N = 768$. On the
        top graphs, the codes all have a rate of $1/2$. On the bottom graphs,
        all the codes have a rate of $2/3$. When the (bit or block) error
        probability is zero, the corresponding point is set to the bottom of the
        graph (thus the vertical lines).%
    }
    \label{fig:gallager_bmc}
\end{figure}

First, we observe that, for a fixed degree distribution, both code rates almost
have the same performance in terms of \acrshort{ber} and \acrshort{bler}. More
interestingly, increasing the total degree ($N d_c$ or $M d_v$) lowers the SNR
needed for a given performance by a few dB (from $1$ dB up to $4$ dB). In fact,
a higher total degree means a more connected factor graph i.e. more information
at each node to correct errors. However, increasing the total degree too much
can be detrimental to the overall performance of the decoder. A more connected
factor graph might increase the probability of having short cycles and increases
the decoding time. In fact, we can see this effect in the results: increasing
the total degree from $(d_v=3, d_c=6)$ (resp.  $(d_v=3, d_c=9)$) to $(d_v=4,
    d_c=8)$ (resp.  $(d_v=4, d_c=12)$) does not lead to a significant SNR
improvement (especially or the rate $2/3$ code). But, during the execution of
the decoder, the codes take much longer to decode.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A DIGRESSION ON CODE PERFORMANCE                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A digression on code performance}

Depending on the average total degree, running the code on my \texttt{Intel
    i5-8250U} machine took up to $0.1$ second per codeword ($N = 768$). This
yields a bit rate of $7680$ bits/s which might seem low compared to the
current desired bit rates (in the order of Gb/s for the best home internet).
To understand why the code seems so slow, it is interesting to take a look
at the \textit{flamegraph} of the execution. This flamegraph is depicted in
\autoref{fig:flamegraph_gallager} (on the digital version of this report, it
is possible to zoom in to read the text). This figure highlights two
drawbacks of \acrshort{bp} decoding:

\begin{itemize}
    \item The $\tanh$ and $\tanh^{-1}$ functions are very expensive to compute
    \item Although easier to manipulate, using a hash table to store the bit to
          check and check to bit messages is detrimental to the decoding
          performance (because of the cost of hashing and the cost of accessing
          the stored values).
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/flamegraph.png}
    \caption{Flamegraph of Belief Propagation LDPC decoding on the BMC channel.
        The horizontal axis represents the proportion of time the execution
        spent in a given function: the more time a function took to execute, the
        larger its band is. The vertical axis represents the call stack of each
        function.%
    }
    \label{fig:flamegraph_gallager}
\end{figure}